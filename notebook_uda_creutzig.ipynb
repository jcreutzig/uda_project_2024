{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user specific setup \n",
    "# this should work fine as default but you might want to store data \n",
    "# other places so feel free to change the paths here\n",
    "\n",
    "zip_folder = 'data_download_zip/' \n",
    "dl_data_folder = 'data/'\n",
    "\n",
    "base_url = 'https://zenodo.org/record/8204334/files/'\n",
    "\n",
    "ds20_url = base_url + 'ds20.zip'\n",
    "ds100_url = base_url + 'ds100.zip'\n",
    "\n",
    "ds20_zipfile = zip_folder + 'ds20.zip'\n",
    "ds100_zipfile = zip_folder  + 'ds100.zip'\n",
    "\n",
    "ds20_data_folder = dl_data_folder + 'ds20/'\n",
    "ds100_data_folder = dl_data_folder + 'ds100/'\n",
    "\n",
    "ds20_model_folder = 'models/ds20/'\n",
    "ds100_model_folder = 'models/ds100/'\n",
    "\n",
    "\n",
    "EDGE_WGT = 9. \n",
    "\n",
    "our_rando_seed = 417417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup.  \n",
    "\n",
    "NL = [4, 5, 6, 7] # number of layers to be trained \n",
    "NC = [20, 30, 40] # number of channels \n",
    "NH = [4, 5, 6, 7] # number of hops \n",
    "\n",
    "hp_idx = [\n",
    "    (nl, nc, nh) \n",
    "    for nl in NL \n",
    "    for nc in NC  \n",
    "    for nh in NH \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict,  List, Callable\n",
    "import os \n",
    "from requests import get \n",
    "import zipfile\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import networkx as nx \n",
    "\n",
    "import torch \n",
    "from torch import tensor\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "from torch_geometric.nn import TAGConv\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data_download_zip/ds20.zip already exists. Set overwrite=True to overwrite\n",
      "File data_download_zip/ds100.zip already exists. Set overwrite=True to overwrite\n"
     ]
    }
   ],
   "source": [
    "# loading data \n",
    "# This will take maybe 30 seconds initially.  \n",
    "# Seecond time you should not notice the lag.  \n",
    "\n",
    "\n",
    "def mkdir_if_not_exist(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def make_path_if_not_exist(file):\n",
    "    folder = os.path.dirname(file)\n",
    "    mkdir_if_not_exist(folder)\n",
    "\n",
    "def load_from_source(url, file, overwrite=False):\n",
    "    make_path_if_not_exist(file)\n",
    "    if not os.path.exists(file) or overwrite:\n",
    "        with open(file, 'wb') as f:\n",
    "            response = get(url)\n",
    "            f.write(response.content)\n",
    "            print(f\"Downloaded {url} to {file}\")\n",
    "            f.close()\n",
    "\n",
    "    else:\n",
    "        print(f\"File {file} already exists. Set overwrite=True to overwrite\")\n",
    "\n",
    "load_from_source(ds20_url, ds20_zipfile)\n",
    "load_from_source(ds100_url, ds100_zipfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now extract from zip files and load the data \n",
    "def extract_zip(zipfile_name, folder):\n",
    "    zf = zipfile.ZipFile(zipfile_name)\n",
    "    zf.extractall(folder)\n",
    "    zf.close()\n",
    "\n",
    "extract_zip(ds20_zipfile, dl_data_folder)\n",
    "extract_zip(ds100_zipfile, dl_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# read in hd5 data \n",
    "# This is quite slow, taking about 3 minutes.  \n",
    "def load_data(ds: str, type:str, data_folder:str, batch_size=500) -> DataLoader:  \n",
    "\n",
    "    folder_name = f\"{data_folder}/{ds}/{type}/\"\n",
    "\n",
    "    file_name_input = f\"{folder_name}/input_data.h5\"\n",
    "    file_name_snbs = f\"{folder_name}/snbs.h5\"\n",
    "\n",
    "    snbs_data = h5py.File(file_name_snbs, 'r')\n",
    "    input_data = h5py.File(file_name_input, 'r')['grids']\n",
    "\n",
    "    grid_data = [\n",
    "        Data(\n",
    "            x = tensor(np.array(id_v['node_features']).reshape(-1, 1), dtype=torch.float),\n",
    "            edge_index = tensor(np.array(id_v['edge_index']).T - 1, dtype=torch.long),\n",
    "            edge_attr = tensor(np.full(shape=id_v['edge_index'].shape[0], fill_value=EDGE_WGT), dtype=torch.float),\n",
    "            y = tensor(np.array(snbs_v), dtype=torch.float)\n",
    "        )\n",
    "        for id_v, snbs_v in zip(input_data.values(), snbs_data.values())\n",
    "    ]\n",
    "\n",
    "    return DataLoader(grid_data, batch_size=batch_size)\n",
    "\n",
    "def load_dataset(ds:str, data_folder: str) -> Dict[str, DataLoader]: \n",
    "    res= dict() \n",
    "    res['train_ds'] = load_data(ds=ds, type='train', data_folder=data_folder)\n",
    "    res['test_ds'] = load_data(ds=ds, type='test', data_folder=data_folder)\n",
    "    res['valid_ds'] = load_data(ds=ds, type='valid', data_folder=data_folder)\n",
    "    return res \n",
    "\n",
    "data_ds20 = load_dataset('ds20', dl_data_folder)\n",
    "data_ds100 = load_dataset('ds100', dl_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[20, 1], edge_index=[2, 54], edge_attr=[54], y=[20])\n"
     ]
    }
   ],
   "source": [
    "# test how the dtaset looks like \n",
    "\n",
    "print(data_ds20['train_ds'].dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAGConvModule(torch.nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, K_hops, activation, batch_norm) -> None:\n",
    "        super().__init__()\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.K_hops = K_hops\n",
    "        self.activation = activation\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        self.conv = TAGConv(\n",
    "            self.channels_in, \n",
    "            self.channels_out, \n",
    "            K=self.K_hops\n",
    "        )\n",
    "        if self.batch_norm:\n",
    "            self.batch_norm_layer = torch.nn.BatchNorm1d(self.channels_out)\n",
    "\n",
    "    def forward(self, data, x):\n",
    "        # Add safety checks\n",
    "        num_nodes = x.size(0)\n",
    "        if data.edge_index.max() >= num_nodes:\n",
    "            raise ValueError(f\"Edge index contains invalid node indices. Max index: {data.edge_index.max()}, num nodes: {num_nodes}\")\n",
    "        \n",
    "        if data.edge_index.min() < 0:\n",
    "            raise ValueError(f\"Edge index contains negative indices: {data.edge_index.min()}\")\n",
    "            \n",
    "        # Apply convolution\n",
    "        x = self.conv(x, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm_layer(x)\n",
    "        \n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "class TAGNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        no_layers: int,\n",
    "        channels: List[int],\n",
    "        activation: List[Callable],\n",
    "        K_hops: List[int],\n",
    "        batch_norm: List[bool],\n",
    "        final_linear_layer: bool,\n",
    "        final_sigmoid_layer: bool = True, \n",
    "    ) -> None:\n",
    "        super(TAGNet, self).__init__()\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.channels = channels\n",
    "        self.activation = activation\n",
    "        self.K_hops = K_hops\n",
    "        self.batch_norm = batch_norm\n",
    "        self.final_linear_layer = final_linear_layer\n",
    "        self.final_sigmoid_layer = final_sigmoid_layer\n",
    "\n",
    "\n",
    "        self.convlist = torch.nn.ModuleList([\n",
    "            TAGConvModule(\n",
    "                channels_in=self.channels[i],\n",
    "                channels_out=self.channels[i+1],\n",
    "                activation=self.activation[i],\n",
    "                K_hops=self.K_hops[i],\n",
    "                batch_norm=self.batch_norm[i]\n",
    "            )\n",
    "            for i in range(self.no_layers)\n",
    "        ])\n",
    "\n",
    "        if self.final_linear_layer:\n",
    "            self.endLinear = torch.nn.Linear(self.channels[-1], 1)\n",
    "        if self.final_sigmoid_layer: \n",
    "            self.endSigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        \n",
    "        for conv in self.convlist:\n",
    "            x = conv(data, x)\n",
    "            \n",
    "        if self.final_linear_layer:\n",
    "            x = self.endLinear(x)\n",
    "        if self.final_sigmoid_layer: \n",
    "            x = self.endSigmoid(x)\n",
    "        \n",
    "        return x.squeeze(-1)  # Match target shape\n",
    "\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "class TAGModule(torch.nn.Module): \n",
    "    def __init__(\n",
    "        self, \n",
    "        channels, \n",
    "        activation,\n",
    "        K_hops,\n",
    "        batch_norm,\n",
    "        final_linear_layer, \n",
    "        final_sigmoid_layer\n",
    "    ) -> None:\n",
    "        \n",
    "        torch.manual_seed(our_rando_seed)\n",
    "        torch.cuda.manual_seed(our_rando_seed)\n",
    "        np.random.seed(our_rando_seed)        \n",
    "\n",
    "        super(TAGModule, self).__init__()\n",
    "        self.model = TAGNet(\n",
    "            no_layers=len(channels) - 1,\n",
    "            channels=channels,\n",
    "            activation=activation,\n",
    "            K_hops=K_hops,\n",
    "            batch_norm=batch_norm,\n",
    "            final_linear_layer=final_linear_layer,\n",
    "            final_sigmoid_layer=final_sigmoid_layer\n",
    "        )\n",
    "        self.device = torch.device('cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.criterion = MSELoss(reduction='mean')\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(), lr=3, momentum=0.9\n",
    "        ) \n",
    "\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(\n",
    "            self.optimizer, step_size=10, gamma=0.1\n",
    "        )\n",
    "\n",
    "        self.r2score = R2Score().to(self.device)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        return self.model(x)\n",
    "\n",
    "    def train_epoch(self, data_loader, threshold=0.1): \n",
    "        self.model.train() \n",
    "        all_labels = torch.Tensor(0).to(self.device)\n",
    "        all_preds = torch.Tensor(0).to(self.device)\n",
    "        correct = 0 \n",
    "        for _, (batch) in enumerate(data_loader):\n",
    "            batch.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = torch.squeeze(self.model.forward(batch))\n",
    "            loss = self.criterion(outputs, batch.y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            correct += torch.sum(( torch.abs(outputs-batch.y) < threshold ))\n",
    "            all_labels = torch.cat([all_labels, batch.y])\n",
    "            all_preds = torch.cat([all_preds, outputs])\n",
    "\n",
    "        accuracy = correct / all_labels.shape[0]\n",
    "        r2_score = self.r2score(all_preds, all_labels)\n",
    "\n",
    "        return accuracy, r2_score\n",
    "\n",
    "    def eval_model(self, data_loader, threshold=0.1): \n",
    "        self.model.eval() \n",
    "        correct = 0 \n",
    "        all_labels = torch.Tensor(0).to(self.device)\n",
    "        all_preds = torch.Tensor(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for _, (batch) in enumerate(data_loader):\n",
    "                batch.to(self.device)\n",
    "                outputs = torch.squeeze(self.model(batch))\n",
    "                correct += torch.sum(( torch.abs(outputs-batch.y) < threshold ))\n",
    "                all_labels = torch.cat([all_labels, batch.y])\n",
    "                all_preds = torch.cat([all_preds, outputs])\n",
    "\n",
    "        accuracy = correct / all_labels.shape[0]\n",
    "        r2_score = self.r2score(all_preds, all_labels)\n",
    "\n",
    "        return accuracy, r2_score\n",
    "        \n",
    "\n",
    "# Update your model initialization\n",
    "tag_net = TAGNet(\n",
    "    no_layers=3,\n",
    "    channels=[1, 32, 32, 1],  # Make sure dimensions match\n",
    "    activation=[torch.nn.ReLU()] * 3,\n",
    "    K_hops=[2] * 3,\n",
    "    batch_norm=[True] * 3, \n",
    "    final_linear_layer=True\n",
    ")\n",
    "\n",
    "tag_module = TAGModule(\n",
    "    channels=[1, 30, 30, 1],\n",
    "    activation=[torch.nn.ReLU()] * 3,\n",
    "    K_hops=[3] * 3,\n",
    "    batch_norm=[True] * 3,\n",
    "    final_linear_layer=False,\n",
    "    final_sigmoid_layer=True\n",
    ")\n",
    "\n",
    "\n",
    "def make_tag_module(num_layers, num_channels, num_hops): \n",
    "    return TAGModule(\n",
    "        channels=[1] + [num_channels] * (num_layers - 1) + [1],\n",
    "        activation=[torch.nn.ReLU()] * num_layers,\n",
    "        K_hops=[num_hops] * num_layers,\n",
    "        batch_norm=[True] * num_layers,\n",
    "        final_linear_layer=False,\n",
    "        final_sigmoid_layer=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use now TAGModule to train model \n",
    "\n",
    "def train_model(tag_module, data_loader, epochs, patience_limit=50, print_at=None):\n",
    "    best_so_far = -np.inf\n",
    "    patienc_eused=0\n",
    "    all_train_acc = [] \n",
    "    all_train_r2 = [] \n",
    "    all_test_acc = [] \n",
    "    all_test_r2 = [] \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_acc, train_r2 = tag_module.train_epoch(data_loader['train_ds'], threshold=0.05)\n",
    "        valid_acc, valid_r2 = tag_module.eval_model(data_loader['valid_ds'], threshold=0.05)\n",
    "        if valid_r2 > best_so_far:\n",
    "            best_so_far = valid_r2\n",
    "            patienc_eused = 0\n",
    "        else:\n",
    "            patienc_eused += 1\n",
    "            if patienc_eused > patience_limit:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        if print_at: \n",
    "            if epoch % print_at == 0:\n",
    "                print(f\"Epoch {epoch}: Train accuracy: {train_acc:.2f}, Train R2: {train_r2:.2f}, Valid accuracy: {valid_acc:.2f}, Valid R2: {valid_r2:.2f}\")\n",
    "\n",
    "        all_train_acc.append(float(train_acc))\n",
    "        all_train_r2.append(float(train_r2.item()))\n",
    "        all_test_acc.append(float(valid_acc))\n",
    "        all_test_r2.append(float(valid_r2.item()))\n",
    "\n",
    "    hist = {\n",
    "        'train_acc': np.array(all_train_acc), \n",
    "        'train_r2': np.array(all_train_r2), \n",
    "        'valid_acc': np.array(all_test_acc), \n",
    "        'valid_r2': np.array(all_test_r2), \n",
    "    }\n",
    "    return hist \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training models \n",
    "model_dict = dict() \n",
    "hist_dict = dict() \n",
    "\n",
    "#make dir trained_models/ if not exists \n",
    "for subdir in [\n",
    "        'trained_models_ds20', 'training_hist_ds20', \n",
    "        'trained_models_ds100', 'training_hist_ds100', \n",
    "    ]:  \n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "\n",
    "# print(\"=\"*20)\n",
    "# print(\"=\"*20) \n",
    "# print(\"20 NODE TRAINING SET\")\n",
    "\n",
    "\n",
    "def train_batch(\n",
    "        index_set, \n",
    "        which='ds20', \n",
    "        overwrite=False, \n",
    "        epochs=400, \n",
    "        patience_limit=400,\n",
    "        ): \n",
    "    training_folder = f'trained_models_{which}/'\n",
    "    hist_folder = f'training_hist_{which}/'\n",
    "\n",
    "    # make folders if not exist \n",
    "    mkdir_if_not_exist(training_folder)\n",
    "    mkdir_if_not_exist(hist_folder)\n",
    "\n",
    "    for idx in index_set: \n",
    "        training_file_name = training_folder + f'model_{str(idx)}.pth'\n",
    "        if os.path.exists(training_file_name) and not overwrite:\n",
    "            print(f\"Model {str(idx)} already trained. Skipping\")\n",
    "            continue\n",
    "\n",
    "        # find data set \n",
    "        if which == 'ds20': \n",
    "            data = data_ds20 \n",
    "        elif which == 'ds100': \n",
    "            data = data_ds100\n",
    "        else:\n",
    "            raise ValueError('Unknown parameter which ' + which)\n",
    "\n",
    "        print(f'Training {str(idx)}..')\n",
    "        model_dict[idx] = make_tag_module(\n",
    "            num_layers=idx[0], \n",
    "            num_channels=idx[1], \n",
    "            num_hops = idx[2]\n",
    "            )\n",
    "        hist_dict[idx] = train_model(\n",
    "            model_dict[idx], \n",
    "            data, \n",
    "            epochs = epochs, \n",
    "            patience_limit=patience_limit, \n",
    "            print_at=50\n",
    "        )\n",
    "\n",
    "        torch.save(model_dict[idx], training_folder + f'model_{str(idx)}.pth') \n",
    "        # transform hist dict into json and save too \n",
    "        tmp_dict = {\n",
    "            k: list(v) \n",
    "            for k, v in hist_dict[idx].items() \n",
    "        }\n",
    "        import json \n",
    "        json.dump(\n",
    "            tmp_dict, \n",
    "            open(f'{hist_folder}/{str(idx)}.pth', 'w') \n",
    "            )\n",
    "\n",
    "    print(\"done.\")\n",
    "\n",
    "# train_batch(index_set=hp_idx,  \n",
    "#             patience_limit=400, epochs = 400)\n",
    "\n",
    "# print(\"=\"*20)\n",
    "# print(\"=\"*20) \n",
    "# print(\"100 NODE TRAINING SET\")\n",
    "\n",
    "# for idx in hp_idx: \n",
    "#     print(\"=\"*20)\n",
    "#     print(f'Training {str(idx)}..')\n",
    "#     model_dict[idx] = make_tag_module(\n",
    "#         num_layers=idx[0], \n",
    "#         num_channels=idx[1], \n",
    "#         num_hops = idx[2]\n",
    "#         )\n",
    "#     hist_dict[idx] = train_model(\n",
    "#         model_dict[idx], \n",
    "#         data_ds20, \n",
    "#         epochs = 400, \n",
    "#         patience_limit=400, \n",
    "#         print_at=50\n",
    "#     )\n",
    "\n",
    "#     torch.save(model_dict[idx], f'trained_models_ds100/model_{str(idx)}.pth') \n",
    "#     # transform hist dict into json and save too \n",
    "#     tmp_dict = {\n",
    "#         k: list(v) \n",
    "#         for k, v in hist_dict[idx].items() \n",
    "#     }\n",
    "#     import json \n",
    "#     json.dump(\n",
    "#         tmp_dict, \n",
    "#         open(f'training_hist_ds100/{str(idx)}.pth', 'w') \n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (4, 20, 4) already trained. Skipping\n",
      "Model (4, 20, 5) already trained. Skipping\n",
      "Model (4, 20, 6) already trained. Skipping\n",
      "Model (4, 20, 7) already trained. Skipping\n",
      "Model (4, 30, 4) already trained. Skipping\n",
      "Training (4, 30, 5)..\n",
      "Epoch 0: Train accuracy: 0.20, Train R2: -2.29, Valid accuracy: 0.23, Valid R2: -1.44\n",
      "Epoch 50: Train accuracy: 0.64, Train R2: 0.65, Valid accuracy: 0.63, Valid R2: 0.64\n",
      "Epoch 100: Train accuracy: 0.68, Train R2: 0.70, Valid accuracy: 0.66, Valid R2: 0.69\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mds20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 52\u001b[0m, in \u001b[0;36mtrain_batch\u001b[0;34m(index_set, which, overwrite, epochs, patience_limit)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m model_dict[idx] \u001b[38;5;241m=\u001b[39m make_tag_module(\n\u001b[1;32m     48\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39midx[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     49\u001b[0m     num_channels\u001b[38;5;241m=\u001b[39midx[\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m     50\u001b[0m     num_hops \u001b[38;5;241m=\u001b[39m idx[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     51\u001b[0m     )\n\u001b[0;32m---> 52\u001b[0m hist_dict[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_dict[idx], training_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# transform hist dict into json and save too \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(tag_module, data_loader, epochs, patience_limit, print_at)\u001b[0m\n\u001b[1;32m      9\u001b[0m all_test_r2 \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 12\u001b[0m     train_acc, train_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtag_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_ds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     valid_acc, valid_r2 \u001b[38;5;241m=\u001b[39m tag_module\u001b[38;5;241m.\u001b[39meval_model(data_loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_ds\u001b[39m\u001b[38;5;124m'\u001b[39m], threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_r2 \u001b[38;5;241m>\u001b[39m best_so_far:\n",
      "Cell \u001b[0;32mIn[8], line 138\u001b[0m, in \u001b[0;36mTAGModule.train_epoch\u001b[0;34m(self, data_loader, threshold)\u001b[0m\n\u001b[1;32m    136\u001b[0m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 138\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    139\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m    140\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[8], line 78\u001b[0m, in \u001b[0;36mTAGNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     75\u001b[0m x \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvlist:\n\u001b[0;32m---> 78\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_linear_layer:\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendLinear(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m, in \u001b[0;36mTAGConvModule.forward\u001b[0;34m(self, data, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdge index contains negative indices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Apply convolution\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm:\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm_layer(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/nn/conv/tag_conv.py:90\u001b[0m, in \u001b[0;36mTAGConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     87\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins[\u001b[38;5;241m0\u001b[39m](x)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lin \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m lin\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:565\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m         aggr_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 565\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    568\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:618\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    603\u001b[0m     inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    607\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:128\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:182\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch_geometric/utils/_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_batch(\n",
    "    which = 'ds20', \n",
    "    index_set=hp_idx,  \n",
    "    patience_limit=400, \n",
    "    epochs = 400\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch(\n",
    "    which = 'ds100', \n",
    "    index_set=hp_idx,  \n",
    "    patience_limit=10, \n",
    "    epochs = 400\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch \n",
    "from torch_geometric.nn import TAGConv\n",
    "import json \n",
    "# read in trained model and training data \n",
    "\n",
    "def read_hist_data(which:str):\n",
    "    hist = dict()\n",
    "    hist_folder = f'training_hist_{which}'\n",
    "    for idx in hp_idx: \n",
    "        hist[idx] = json.load(open(f'{hist_folder}/{str(idx)}.pth'))\n",
    "    return hist\n",
    "\n",
    "\n",
    "# load TAG model \n",
    "\n",
    "def  load_tag_models(which: str='ds20', my_idx: list = hp_idx): \n",
    "    model_dict = dict() \n",
    "    training_folder = f'trained_models_{which}/'\n",
    "    for idx in my_idx: \n",
    "        model_dict[idx] = torch.load(training_folder + f'model_{str(idx)}.pth')\n",
    "    \n",
    "    return model_dict \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trained_models_ds20/model_(4, 20, 2).pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_tag_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mds20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 21\u001b[0m, in \u001b[0;36mload_tag_models\u001b[0;34m(which, my_idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m training_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_models_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhich\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m my_idx: \n\u001b[0;32m---> 21\u001b[0m     model_dict[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/uda_project_autumn_2024/lib/python3.10/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trained_models_ds20/model_(4, 20, 2).pth'"
     ]
    }
   ],
   "source": [
    "load_tag_models(which='ds20', my_idx=[(4,20,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "# we dissect the indices again \n",
    "fig, axs = plt.subplots(len(NL), len(NC), figsize=(15, 15))\n",
    "\n",
    "for i, nl in enumerate(NL): \n",
    "    for j, nc in enumerate(NC): \n",
    "        ax = axs[i,j]\n",
    "        for nh in NH: \n",
    "            ts = hist_dict[(nl, nc, nh)]['valid_r2']\n",
    "            L = len(ts)\n",
    "            epochs = np.arange(L)\n",
    "            eps = epochs[25:]\n",
    "            t = ts[25:]\n",
    "            l = str(nh) + \" hops\"\n",
    "            ax.plot(eps, t, label=l)\n",
    "            ax.legend()\n",
    "            ax.set_ylim(0.4,0.9)\n",
    "            ax.grid()\n",
    "            ax.set_title(f\"{nl} layers, {nc} channels\")\n",
    "\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustration of in-/output \n",
    "\n",
    "def plot_graph(\n",
    "        data, node_labels, ax=None, \n",
    "        title=None, node_size=100, \n",
    "        cmap='RdYlGn',\n",
    "        vmin=None, vmax=None,\n",
    "        add_colorbar=False,\n",
    "        colorbar_label=None):\n",
    "    \n",
    "    edges = data.edge_index.numpy()\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(node_labels.shape[0]))\n",
    "    G.add_edges_from(edges.T)\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, ax=ax,\n",
    "        node_color='black',  # ring color\n",
    "        node_size=node_size  + min(max(40., 0.4*node_size), 20.),  # slightly larger size for the ring\n",
    "    )\n",
    "    # Draw the graph\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        G, pos, ax=ax, node_color=node_labels, \n",
    "        cmap=cmap, node_size=node_size,\n",
    "        vmin=vmin, vmax=vmax  # Add these parameters for consistent color scaling\n",
    "        )\n",
    "    edges = nx.draw_networkx_edges(G, pos, ax=ax)\n",
    "    \n",
    "    if add_colorbar:\n",
    "        # Add colorbar with percentage formatting\n",
    "        cbar = plt.colorbar(nodes, ax=ax)\n",
    "        if colorbar_label:\n",
    "            cbar.set_label(colorbar_label)\n",
    "        cbar.ax.yaxis.set_major_formatter(\n",
    "            PercentFormatter(xmax=1.0, decimals=0)\n",
    "            )\n",
    "\n",
    "def plt_snbs(data, pred_snbs, node_size=100):\n",
    "\n",
    "    P = data.x.numpy()\n",
    "    snbs = data.y.numpy()\n",
    "\n",
    "    # Create the plot with equal sizes and shared colorbar\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    gs = fig.add_gridspec(1, 3, width_ratios=[1, 1, 1.2])  # Slightly wider last subplot for colorbar\n",
    "\n",
    "    axs = [fig.add_subplot(gs[0, i]) for i in range(3)]\n",
    "\n",
    "    # Get the full range of values for consistent colormap\n",
    "    vmin = min(snbs.min(), pred_snbs.min())\n",
    "    vmax = max(snbs.max(), pred_snbs.max())\n",
    "\n",
    "\n",
    "    # Plot each graph\n",
    "\n",
    "    # first graph gets a purple/orange colormap \n",
    "    plot_graph(\n",
    "        data, P, ax=axs[0], \n",
    "        title='Grid, Source (purple) / Sink (red)', \n",
    "        vmin=-1, vmax=1, cmap=mcolors.ListedColormap(['purple', 'orange']), \n",
    "        node_size=node_size\n",
    "        )\n",
    "\n",
    "    plot_graph(data, snbs, ax=axs[1], title='True SNBS', vmin=vmin, vmax=vmax, \n",
    "        node_size=node_size)\n",
    "    nodes = plot_graph(data, pred_snbs, ax=axs[2], title='Predicted SNBS', \n",
    "                    vmin=vmin, vmax=vmax, add_colorbar=True, \n",
    "                    colorbar_label='SNBS', \n",
    "        node_size=node_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "data = data_ds100['train_ds'].dataset[0]\n",
    "pred_snbs = tag_module(data).detach().numpy()\n",
    "plt_snbs(data, pred_snbs, node_size=30)\n",
    "plt.savefig('sample_graph_100.png')\n",
    "plt.show()\n",
    "\n",
    "data = data_ds20['train_ds'].dataset[0]\n",
    "pred_snbs = tag_module(data).detach().numpy()\n",
    "plt_snbs(data, pred_snbs, node_size=100)\n",
    "plt.savefig('sample_graph_20.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uda_project_autumn_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
