{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user specific setup \n",
    "# this should work fine as default but you might want to store data \n",
    "# other places so feel free to change the paths here\n",
    "\n",
    "zip_folder = 'data_download_zip/' \n",
    "dl_data_folder = 'data/'\n",
    "\n",
    "base_url = 'https://zenodo.org/record/8204334/files/'\n",
    "\n",
    "ds20_url = base_url + 'ds20.zip'\n",
    "ds100_url = base_url + 'ds100.zip'\n",
    "texas_url = base_url + 'texas.zip'\n",
    "\n",
    "ds20_zipfile = zip_folder + 'ds20.zip'\n",
    "ds100_zipfile = zip_folder  + 'ds100.zip'\n",
    "texas_zipfile = zip_folder + 'texas.zip'\n",
    "\n",
    "ds20_data_folder = dl_data_folder + 'ds20/'\n",
    "ds100_data_folder = dl_data_folder + 'ds100/'\n",
    "texas_data_folder = dl_data_folder + 'texas/'\n",
    "\n",
    "ds20_model_folder = 'models/ds20/'\n",
    "ds100_model_folder = 'models/ds100/'\n",
    "texas_model_folder = 'models/texas/'\n",
    "\n",
    "EDGE_WGT = 9. \n",
    "\n",
    "our_rando_seed = 417417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import tensor\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "from torch_geometric.nn import TAGConv \n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data \n",
    "import pandas as pd \n",
    "from typing import List, Dict, Callable  \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx \n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data_download_zip/ds20.zip already exists. Set overwrite=True to overwrite\n",
      "File data_download_zip/ds100.zip already exists. Set overwrite=True to overwrite\n",
      "File data_download_zip/texas.zip already exists. Set overwrite=True to overwrite\n"
     ]
    }
   ],
   "source": [
    "# loading data \n",
    "# This will take maybe 30 seconds initially.  \n",
    "# Seecond time you should not notice the lag.  \n",
    "\n",
    "import os \n",
    "from requests import get \n",
    "\n",
    "def mkdir_if_not_exist(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def make_path_if_not_exist(file):\n",
    "    folder = os.path.dirname(file)\n",
    "    mkdir_if_not_exist(folder)\n",
    "\n",
    "def load_from_source(url, file, overwrite=False):\n",
    "    make_path_if_not_exist(file)\n",
    "    if not os.path.exists(file) or overwrite:\n",
    "        with open(file, 'wb') as f:\n",
    "            response = get(url)\n",
    "            f.write(response.content)\n",
    "            print(f\"Downloaded {url} to {file}\")\n",
    "            f.close()\n",
    "\n",
    "    else:\n",
    "        print(f\"File {file} already exists. Set overwrite=True to overwrite\")\n",
    "\n",
    "load_from_source(ds20_url, ds20_zipfile)\n",
    "load_from_source(ds100_url, ds100_zipfile)\n",
    "load_from_source(texas_url, texas_zipfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# now extract from zip files and load the data \n",
    "\n",
    "import zipfile\n",
    "\n",
    "def extract_zip(zipfile_name, folder):\n",
    "    zf = zipfile.ZipFile(zipfile_name)\n",
    "    zf.extractall(folder)\n",
    "    zf.close()\n",
    "\n",
    "extract_zip(ds20_zipfile, dl_data_folder)\n",
    "extract_zip(ds100_zipfile, dl_data_folder)\n",
    "\n",
    "# re-structure data so we can throw that into the data loader \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_ds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m load_data(ds\u001b[38;5;241m=\u001b[39mds, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, data_folder\u001b[38;5;241m=\u001b[39mdata_folder)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res \n\u001b[1;32m---> 35\u001b[0m data_ds20 \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mds20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_data_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m data_ds100 \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds100\u001b[39m\u001b[38;5;124m'\u001b[39m, dl_data_folder)\n",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(ds, data_folder)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(ds:\u001b[38;5;28mstr\u001b[39m, data_folder: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, DataLoader]: \n\u001b[0;32m     29\u001b[0m     res\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m() \n\u001b[1;32m---> 30\u001b[0m     res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_ds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_ds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m load_data(ds\u001b[38;5;241m=\u001b[39mds, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, data_folder\u001b[38;5;241m=\u001b[39mdata_folder)\n\u001b[0;32m     32\u001b[0m     res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_ds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m load_data(ds\u001b[38;5;241m=\u001b[39mds, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, data_folder\u001b[38;5;241m=\u001b[39mdata_folder)\n",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(ds, type, data_folder, batch_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m snbs_data \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(file_name_snbs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m input_data \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(file_name_input, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 16\u001b[0m grid_data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m     Data(\n\u001b[0;32m     18\u001b[0m         x \u001b[38;5;241m=\u001b[39m tensor(np\u001b[38;5;241m.\u001b[39marray(id_v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_features\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat),\n\u001b[0;32m     19\u001b[0m         edge_index \u001b[38;5;241m=\u001b[39m tensor(np\u001b[38;5;241m.\u001b[39marray(id_v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[0;32m     20\u001b[0m         edge_attr \u001b[38;5;241m=\u001b[39m tensor(np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39mid_v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], fill_value\u001b[38;5;241m=\u001b[39mEDGE_WGT), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat),\n\u001b[0;32m     21\u001b[0m         y \u001b[38;5;241m=\u001b[39m tensor(np\u001b[38;5;241m.\u001b[39marray(snbs_v), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m id_v, snbs_v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_data\u001b[38;5;241m.\u001b[39mvalues(), snbs_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     24\u001b[0m ]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataLoader(grid_data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m snbs_data \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(file_name_snbs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m input_data \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(file_name_input, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m grid_data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m     Data(\n\u001b[0;32m     18\u001b[0m         x \u001b[38;5;241m=\u001b[39m tensor(np\u001b[38;5;241m.\u001b[39marray(id_v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_features\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat),\n\u001b[1;32m---> 19\u001b[0m         edge_index \u001b[38;5;241m=\u001b[39m tensor(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_v\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medge_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[0;32m     20\u001b[0m         edge_attr \u001b[38;5;241m=\u001b[39m tensor(np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39mid_v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], fill_value\u001b[38;5;241m=\u001b[39mEDGE_WGT), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat),\n\u001b[0;32m     21\u001b[0m         y \u001b[38;5;241m=\u001b[39m tensor(np\u001b[38;5;241m.\u001b[39marray(snbs_v), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m id_v, snbs_v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_data\u001b[38;5;241m.\u001b[39mvalues(), snbs_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     24\u001b[0m ]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataLoader(grid_data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nbjce1\\Anaconda3\\envs\\uda_project_autumn_2024\\lib\\site-packages\\h5py\\_hl\\dataset.py:1091\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\nbjce1\\Anaconda3\\envs\\uda_project_autumn_2024\\lib\\site-packages\\h5py\\_hl\\dataset.py:1047\u001b[0m, in \u001b[0;36mDataset.read_direct\u001b[1;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     dest_sel \u001b[38;5;241m=\u001b[39m sel\u001b[38;5;241m.\u001b[39mselect(dest\u001b[38;5;241m.\u001b[39mshape, dest_sel)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mspace \u001b[38;5;129;01min\u001b[39;00m dest_sel\u001b[38;5;241m.\u001b[39mbroadcast(source_sel\u001b[38;5;241m.\u001b[39marray_shape):\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# read in hd5 data \n",
    "# This is quite slow, taking about 3 minutes.  \n",
    "\n",
    "\n",
    "\n",
    "def load_data(ds: str, type:str, data_folder:str, batch_size=500) -> DataLoader:  \n",
    "\n",
    "    folder_name = f\"{data_folder}/{ds}/{type}/\"\n",
    "\n",
    "    file_name_input = f\"{folder_name}/input_data.h5\"\n",
    "    file_name_snbs = f\"{folder_name}/snbs.h5\"\n",
    "\n",
    "    snbs_data = h5py.File(file_name_snbs, 'r')\n",
    "    input_data = h5py.File(file_name_input, 'r')['grids']\n",
    "\n",
    "    grid_data = [\n",
    "        Data(\n",
    "            x = tensor(np.array(id_v['node_features']).reshape(-1, 1), dtype=torch.float),\n",
    "            edge_index = tensor(np.array(id_v['edge_index']).T - 1, dtype=torch.long),\n",
    "            edge_attr = tensor(np.full(shape=id_v['edge_index'].shape[0], fill_value=EDGE_WGT), dtype=torch.float),\n",
    "            y = tensor(np.array(snbs_v), dtype=torch.float)\n",
    "        )\n",
    "        for id_v, snbs_v in zip(input_data.values(), snbs_data.values())\n",
    "    ]\n",
    "\n",
    "    return DataLoader(grid_data, batch_size=batch_size)\n",
    "\n",
    "def load_dataset(ds:str, data_folder: str) -> Dict[str, DataLoader]: \n",
    "    res= dict() \n",
    "    res['train_ds'] = load_data(ds=ds, type='train', data_folder=data_folder)\n",
    "    res['test_ds'] = load_data(ds=ds, type='test', data_folder=data_folder)\n",
    "    res['valid_ds'] = load_data(ds=ds, type='valid', data_folder=data_folder)\n",
    "    return res \n",
    "\n",
    "data_ds20 = load_dataset('ds20', dl_data_folder)\n",
    "data_ds100 = load_dataset('ds100', dl_data_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_from_source, extract_zip, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9999, 1.0000, 0.9807, 0.8151, 0.9770, 0.8541, 0.8983, 0.7800, 0.8480,\n",
      "        0.8558, 0.9656, 0.9257, 0.8025, 0.6902, 0.6636, 0.8054, 0.7192, 0.7492,\n",
      "        0.8234, 0.7749])\n"
     ]
    }
   ],
   "source": [
    "# test how the dtaset looks like \n",
    "\n",
    "print(data_ds20['train_ds'].dataset[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAGConvModule(torch.nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, K_hops, activation, batch_norm) -> None:\n",
    "        super().__init__()\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.K_hops = K_hops\n",
    "        self.activation = activation\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        self.conv = TAGConv(\n",
    "            self.channels_in, \n",
    "            self.channels_out, \n",
    "            K=self.K_hops\n",
    "        )\n",
    "        if self.batch_norm:\n",
    "            self.batch_norm_layer = torch.nn.BatchNorm1d(self.channels_out)\n",
    "\n",
    "    def forward(self, data, x):\n",
    "        # Add safety checks\n",
    "        num_nodes = x.size(0)\n",
    "        if data.edge_index.max() >= num_nodes:\n",
    "            raise ValueError(f\"Edge index contains invalid node indices. Max index: {data.edge_index.max()}, num nodes: {num_nodes}\")\n",
    "        \n",
    "        if data.edge_index.min() < 0:\n",
    "            raise ValueError(f\"Edge index contains negative indices: {data.edge_index.min()}\")\n",
    "            \n",
    "        # Apply convolution\n",
    "        x = self.conv(x, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm_layer(x)\n",
    "        \n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "class TAGNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        no_layers: int,\n",
    "        channels: List[int],\n",
    "        activation: List[Callable],\n",
    "        K_hops: List[int],\n",
    "        batch_norm: List[bool],\n",
    "        final_linear_layer: bool,\n",
    "        final_sigmoid_layer: bool = True, \n",
    "    ) -> None:\n",
    "        super(TAGNet, self).__init__()\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.channels = channels\n",
    "        self.activation = activation\n",
    "        self.K_hops = K_hops\n",
    "        self.batch_norm = batch_norm\n",
    "        self.final_linear_layer = final_linear_layer\n",
    "        self.final_sigmoid_layer = final_sigmoid_layer\n",
    "\n",
    "\n",
    "        self.convlist = torch.nn.ModuleList([\n",
    "            TAGConvModule(\n",
    "                channels_in=self.channels[i],\n",
    "                channels_out=self.channels[i+1],\n",
    "                activation=self.activation[i],\n",
    "                K_hops=self.K_hops[i],\n",
    "                batch_norm=self.batch_norm[i]\n",
    "            )\n",
    "            for i in range(self.no_layers)\n",
    "        ])\n",
    "\n",
    "        if self.final_linear_layer:\n",
    "            self.endLinear = torch.nn.Linear(self.channels[-1], 1)\n",
    "        if self.final_sigmoid_layer: \n",
    "            self.endSigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        \n",
    "        for conv in self.convlist:\n",
    "            x = conv(data, x)\n",
    "            \n",
    "        if self.final_linear_layer:\n",
    "            x = self.endLinear(x)\n",
    "        if self.final_sigmoid_layer: \n",
    "            x = self.endSigmoid(x)\n",
    "        \n",
    "        return x.squeeze(-1)  # Match target shape\n",
    "\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "class TAGModule(torch.nn.Module): \n",
    "    def __init__(\n",
    "        self, \n",
    "        channels, \n",
    "        activation,\n",
    "        K_hops,\n",
    "        batch_norm,\n",
    "        final_linear_layer, \n",
    "        final_sigmoid_layer\n",
    "    ) -> None:\n",
    "        \n",
    "        torch.manual_seed(our_rando_seed)\n",
    "        torch.cuda.manual_seed(our_rando_seed)\n",
    "        np.random.seed(our_rando_seed)        \n",
    "\n",
    "        super(TAGModule, self).__init__()\n",
    "        self.model = TAGNet(\n",
    "            no_layers=len(channels) - 1,\n",
    "            channels=channels,\n",
    "            activation=activation,\n",
    "            K_hops=K_hops,\n",
    "            batch_norm=batch_norm,\n",
    "            final_linear_layer=final_linear_layer,\n",
    "            final_sigmoid_layer=final_sigmoid_layer\n",
    "        )\n",
    "        self.device = torch.device('cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.criterion = MSELoss(reduction='mean')\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(), lr=3, momentum=0.9\n",
    "        ) \n",
    "\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(\n",
    "            self.optimizer, step_size=10, gamma=0.1\n",
    "        )\n",
    "\n",
    "        self.r2score = R2Score().to(self.device)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        return self.model(x)\n",
    "\n",
    "    def train_epoch(self, data_loader, threshold=0.1): \n",
    "        self.model.train() \n",
    "        all_labels = torch.Tensor(0).to(self.device)\n",
    "        all_preds = torch.Tensor(0).to(self.device)\n",
    "        correct = 0 \n",
    "        for _, (batch) in enumerate(data_loader):\n",
    "            batch.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = torch.squeeze(self.model.forward(batch))\n",
    "            loss = self.criterion(outputs, batch.y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            correct += torch.sum(( torch.abs(outputs-batch.y) < threshold ))\n",
    "            all_labels = torch.cat([all_labels, batch.y])\n",
    "            all_preds = torch.cat([all_preds, outputs])\n",
    "\n",
    "        accuracy = correct / all_labels.shape[0]\n",
    "        r2_score = self.r2score(all_preds, all_labels)\n",
    "\n",
    "        return accuracy, r2_score\n",
    "\n",
    "    def eval_model(self, data_loader, threshold=0.1): \n",
    "        self.model.eval() \n",
    "        correct = 0 \n",
    "        all_labels = torch.Tensor(0).to(self.device)\n",
    "        all_preds = torch.Tensor(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for _, (batch) in enumerate(data_loader):\n",
    "                batch.to(self.device)\n",
    "                outputs = torch.squeeze(self.model(batch))\n",
    "                correct += torch.sum(( torch.abs(outputs-batch.y) < threshold ))\n",
    "                all_labels = torch.cat([all_labels, batch.y])\n",
    "                all_preds = torch.cat([all_preds, outputs])\n",
    "\n",
    "        accuracy = correct / all_labels.shape[0]\n",
    "        r2_score = self.r2score(all_preds, all_labels)\n",
    "\n",
    "        return accuracy, r2_score\n",
    "        \n",
    "\n",
    "# Update your model initialization\n",
    "tag_net = TAGNet(\n",
    "    no_layers=3,\n",
    "    channels=[1, 32, 32, 1],  # Make sure dimensions match\n",
    "    activation=[torch.nn.ReLU()] * 3,\n",
    "    K_hops=[2] * 3,\n",
    "    batch_norm=[True] * 3, \n",
    "    final_linear_layer=True\n",
    ")\n",
    "\n",
    "tag_module = TAGModule(\n",
    "    channels=[1, 30, 30, 1],\n",
    "    activation=[torch.nn.ReLU()] * 3,\n",
    "    K_hops=[3] * 3,\n",
    "    batch_norm=[True] * 3,\n",
    "    final_linear_layer=False,\n",
    "    final_sigmoid_layer=True\n",
    ")\n",
    "\n",
    "\n",
    "def make_tag_module(num_layers, num_channels, num_hops): \n",
    "    return TAGModule(\n",
    "        channels=[1] + [num_channels] * (num_layers - 1) + [1],\n",
    "        activation=[torch.nn.ReLU()] * num_layers,\n",
    "        K_hops=[num_hops] * num_layers,\n",
    "        batch_norm=[True] * num_layers,\n",
    "        final_linear_layer=False,\n",
    "        final_sigmoid_layer=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use now TAGModule to train model \n",
    "\n",
    "\n",
    "def train_model(tag_module, data_loader, epochs, patience_limit=50, print_at=None):\n",
    "    best_so_far = -np.inf\n",
    "    patienc_eused=0\n",
    "    all_train_acc = [] \n",
    "    all_train_r2 = [] \n",
    "    all_test_acc = [] \n",
    "    all_test_r2 = [] \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_acc, train_r2 = tag_module.train_epoch(data_loader['train_ds'], threshold=0.05)\n",
    "        valid_acc, valid_r2 = tag_module.eval_model(data_loader['valid_ds'], threshold=0.05)\n",
    "        if valid_r2 > best_so_far:\n",
    "            best_so_far = valid_r2\n",
    "            patienc_eused = 0\n",
    "        else:\n",
    "            patienc_eused += 1\n",
    "            if patienc_eused > patience_limit:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        if print_at: \n",
    "            if epoch % print_at == 0:\n",
    "                print(f\"Epoch {epoch}: Train accuracy: {train_acc:.2f}, Train R2: {train_r2:.2f}, Valid accuracy: {valid_acc:.2f}, Valid R2: {valid_r2:.2f}\")\n",
    "\n",
    "        all_train_acc.append(float(train_acc))\n",
    "        all_train_r2.append(float(train_r2.item()))\n",
    "        all_test_acc.append(float(valid_acc))\n",
    "        all_test_r2.append(float(valid_r2.item()))\n",
    "\n",
    "    hist = {\n",
    "        'train_acc': np.array(all_train_acc), \n",
    "        'train_r2': np.array(all_train_r2), \n",
    "        'valid_acc': np.array(all_test_acc), \n",
    "        'valid_r2': np.array(all_test_r2), \n",
    "    }\n",
    "    return hist \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "====================\n",
      "20 NODE TRAINING SET\n",
      "====================\n",
      "Training (4, 20, 4)..\n",
      "Epoch 0: Train accuracy: 0.20, Train R2: -2.29, Valid accuracy: 0.22, Valid R2: -1.67\n",
      "Epoch 10: Train accuracy: 0.57, Train R2: 0.50, Valid accuracy: 0.56, Valid R2: 0.48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 35\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m model_dict[idx] \u001b[38;5;241m=\u001b[39m make_tag_module(\n\u001b[0;32m     31\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39midx[\u001b[38;5;241m0\u001b[39m], \n\u001b[0;32m     32\u001b[0m     num_channels\u001b[38;5;241m=\u001b[39midx[\u001b[38;5;241m1\u001b[39m], \n\u001b[0;32m     33\u001b[0m     num_hops \u001b[38;5;241m=\u001b[39m idx[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m hist_dict[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_ds20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_dict[idx], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_models_ds20/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# transform hist dict into json and save too \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(tag_module, data_loader, epochs, patience_limit, print_at)\u001b[0m\n\u001b[0;32m     10\u001b[0m all_test_r2 \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 13\u001b[0m     train_acc, train_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtag_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_ds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     valid_acc, valid_r2 \u001b[38;5;241m=\u001b[39m tag_module\u001b[38;5;241m.\u001b[39meval_model(data_loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_ds\u001b[39m\u001b[38;5;124m'\u001b[39m], threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_r2 \u001b[38;5;241m>\u001b[39m best_so_far:\n",
      "Cell \u001b[1;32mIn[15], line 135\u001b[0m, in \u001b[0;36mTAGModule.train_epoch\u001b[1;34m(self, data_loader, threshold)\u001b[0m\n\u001b[0;32m    133\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    134\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[0;32m    136\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nbjce1\\Anaconda3\\envs\\uda_project_autumn_2024\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32mc:\\Users\\nbjce1\\Anaconda3\\envs\\uda_project_autumn_2024\\lib\\site-packages\\torch_geometric\\data\\batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nbjce1\\Anaconda3\\envs\\uda_project_autumn_2024\\lib\\site-packages\\torch_geometric\\data\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (add_batch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stores[\u001b[38;5;241m0\u001b[39m], NodeStorage)\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m stores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcan_infer_num_nodes):\n\u001b[0;32m    142\u001b[0m         repeats \u001b[38;5;241m=\u001b[39m [store\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores]\n\u001b[1;32m--> 143\u001b[0m         out_store\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m         out_store\u001b[38;5;241m.\u001b[39mptr \u001b[38;5;241m=\u001b[39m cumsum(torch\u001b[38;5;241m.\u001b[39mtensor(repeats, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, slice_dict, inc_dict\n",
      "File \u001b[1;32mc:\\Users\\nbjce1\\Anaconda3\\envs\\uda_project_autumn_2024\\lib\\site-packages\\torch_geometric\\data\\collate.py:315\u001b[0m, in \u001b[0;36mrepeat_interleave\u001b[1;34m(repeats, device)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat_interleave\u001b[39m(\n\u001b[0;32m    312\u001b[0m     repeats: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    313\u001b[0m     device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 315\u001b[0m     outs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfull((n, ), i, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(repeats)]\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nbjce1\\Anaconda3\\envs\\uda_project_autumn_2024\\lib\\site-packages\\torch_geometric\\data\\collate.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat_interleave\u001b[39m(\n\u001b[0;32m    312\u001b[0m     repeats: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    313\u001b[0m     device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 315\u001b[0m     outs \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(repeats)]\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "NL = [4, 5, 6, 7] \n",
    "NC = [20, 30, 40]  \n",
    "NH = [4, 5, 6, 7]\n",
    "\n",
    "hp_idx = [\n",
    "    (nl, nc, nh) \n",
    "    for nl in NL \n",
    "    for nc in NC  \n",
    "    for nh in NH \n",
    "]\n",
    "\n",
    "model_dict = dict() \n",
    "hist_dict = dict() \n",
    "\n",
    "#make dir trained_models/ if not exists \n",
    "for subdir in [\n",
    "        'trained_models_ds20', 'training_hist_ds20', \n",
    "        'trained_models_ds100', 'training_hist_ds100', \n",
    "    ]:  \n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"=\"*20) \n",
    "print(\"20 NODE TRAINING SET\")\n",
    "\n",
    "for idx in hp_idx: \n",
    "    print(\"=\"*20)\n",
    "    print(f'Training {str(idx)}..')\n",
    "    model_dict[idx] = make_tag_module(\n",
    "        num_layers=idx[0], \n",
    "        num_channels=idx[1], \n",
    "        num_hops = idx[2]\n",
    "        )\n",
    "    hist_dict[idx] = train_model(\n",
    "        model_dict[idx], \n",
    "        data_ds20, \n",
    "        epochs = 400, \n",
    "        patience_limit=10, \n",
    "        print_at=10\n",
    "    )\n",
    "\n",
    "    torch.save(model_dict[idx], f'trained_models_ds20/model_{str(idx)}.pth') \n",
    "    # transform hist dict into json and save too \n",
    "    tmp_dict = {\n",
    "        k: list(v) \n",
    "        for k, v in hist_dict[idx].items() \n",
    "    }\n",
    "    import json \n",
    "    json.dump(\n",
    "        tmp_dict, \n",
    "        open(f'training_hist_ds20/{str(idx)}.pth', 'w') \n",
    "        )\n",
    "\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"=\"*20) \n",
    "print(\"100 NODE TRAINING SET\")\n",
    "\n",
    "for idx in hp_idx: \n",
    "    print(\"=\"*20)\n",
    "    print(f'Training {str(idx)}..')\n",
    "    model_dict[idx] = make_tag_module(\n",
    "        num_layers=idx[0], \n",
    "        num_channels=idx[1], \n",
    "        num_hops = idx[2]\n",
    "        )\n",
    "    hist_dict[idx] = train_model(\n",
    "        model_dict[idx], \n",
    "        data_ds20, \n",
    "        epochs = 400, \n",
    "        patience_limit=10, \n",
    "        print_at=10\n",
    "    )\n",
    "\n",
    "    torch.save(model_dict[idx], f'trained_models_ds100/model_{str(idx)}.pth') \n",
    "    # transform hist dict into json and save too \n",
    "    tmp_dict = {\n",
    "        k: list(v) \n",
    "        for k, v in hist_dict[idx].items() \n",
    "    }\n",
    "    import json \n",
    "    json.dump(\n",
    "        tmp_dict, \n",
    "        open(f'training_hist_ds100/{str(idx)}.pth', 'w') \n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(4, 20, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m ax \u001b[38;5;241m=\u001b[39m axs[i,j]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nh \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]: \n\u001b[1;32m----> 9\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[43mhist_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_r2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ts))\n\u001b[0;32m     11\u001b[0m     idx_plt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m25\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ts))\n",
      "\u001b[1;31mKeyError\u001b[0m: (4, 20, 4)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "# we dissect the indices again \n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "for i, nl in enumerate([4, 5, 6]): \n",
    "    for j, nc in enumerate([20, 30, 50]): \n",
    "        ax = axs[i,j]\n",
    "        for nh in [4, 5, 6]: \n",
    "            ts = hist_dict[(nl, nc, nh)]['valid_r2']\n",
    "            epochs = np.arange(len(ts))\n",
    "            idx_plt = np.arange(25, len(ts))\n",
    "            ax.plot(epochs[idx_plt], ts[idx_plt], label=str(nh) + \" hops\")\n",
    "            ax.legend()\n",
    "            ax.set_ylim(0.4,0.8)\n",
    "            ax.grid()\n",
    "            ax.set_title(f\"{nl} layers, {nc} channels\")\n",
    "\n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now extract some random graph and color it with red-green color map based on the label\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx \n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "def plot_graph(\n",
    "        data, node_labels, ax=None, \n",
    "        title=None, node_size=100, \n",
    "        legend_cmap=None):\n",
    "    \n",
    "    edges = data.edge_index.numpy()\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(node_labels.shape[0]))\n",
    "    G.add_edges_from(edges.T)\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "    \n",
    "    # Draw the graph\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        G, pos, ax=ax, node_color=node_labels, \n",
    "        cmap='RdYlGn', node_size=node_size\n",
    "        )\n",
    "    edges = nx.draw_networkx_edges(G, pos, ax=ax)\n",
    "    \n",
    "    if legend_cmap:\n",
    "        # Add colorbar with percentage formatting \n",
    "        # name legend_cmap to put in as label of legend \n",
    "        cbar = plt.colorbar(nodes, ax=ax)\n",
    "        cbar.set_label(legend_cmap)\n",
    "        cbar.ax.yaxis.set_major_formatter(\n",
    "            PercentFormatter(xmax=1.0, decimals=0)\n",
    "            )\n",
    "    \n",
    "    return ax\n",
    "\n",
    "data = data_ds20['train_ds'].dataset[0]\n",
    "snbs = data.y.numpy()   \n",
    "P = data.x.numpy() \n",
    "pred_snbs = tag_module(data).detach().numpy()\n",
    "\n",
    "_, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "plot_graph(data, P, ax=axs[0], title='Source/Sink')\n",
    "plot_graph(data, snbs, ax=axs[1], title='True SNBS', legend_cmap=\"SNBS\")\n",
    "plot_graph(data, pred_snbs, ax=axs[2], title='Predicted SNBS', legend_cmap=\"predicted SNBS\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_graph(\n",
    "        data, node_labels, ax=None, \n",
    "        title=None, node_size=100, \n",
    "        cmap='RdYlGn',\n",
    "        vmin=None, vmax=None,\n",
    "        add_colorbar=False,\n",
    "        colorbar_label=None):\n",
    "    \n",
    "    edges = data.edge_index.numpy()\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(node_labels.shape[0]))\n",
    "    G.add_edges_from(edges.T)\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, ax=ax,\n",
    "        node_color='black',  # ring color\n",
    "        node_size=node_size  + min(max(40., 0.4*node_size), 20.),  # slightly larger size for the ring\n",
    "    )\n",
    "    # Draw the graph\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        G, pos, ax=ax, node_color=node_labels, \n",
    "        cmap=cmap, node_size=node_size,\n",
    "        vmin=vmin, vmax=vmax  # Add these parameters for consistent color scaling\n",
    "        )\n",
    "    edges = nx.draw_networkx_edges(G, pos, ax=ax)\n",
    "    \n",
    "    if add_colorbar:\n",
    "        # Add colorbar with percentage formatting\n",
    "        cbar = plt.colorbar(nodes, ax=ax)\n",
    "        if colorbar_label:\n",
    "            cbar.set_label(colorbar_label)\n",
    "        cbar.ax.yaxis.set_major_formatter(\n",
    "            PercentFormatter(xmax=1.0, decimals=0)\n",
    "            )\n",
    "    \n",
    "\n",
    "\n",
    "def plt_snbs(data, pred_snbs, node_size=100):\n",
    "\n",
    "    P = data.x.numpy()\n",
    "    snbs = data.y.numpy()\n",
    "\n",
    "    # Create the plot with equal sizes and shared colorbar\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    gs = fig.add_gridspec(1, 3, width_ratios=[1, 1, 1.2])  # Slightly wider last subplot for colorbar\n",
    "\n",
    "    axs = [fig.add_subplot(gs[0, i]) for i in range(3)]\n",
    "\n",
    "    # Get the full range of values for consistent colormap\n",
    "    vmin = min(snbs.min(), pred_snbs.min())\n",
    "    vmax = max(snbs.max(), pred_snbs.max())\n",
    "\n",
    "\n",
    "    # Plot each graph\n",
    "\n",
    "    # first graph gets a purple/orange colormap \n",
    "    plot_graph(\n",
    "        data, P, ax=axs[0], \n",
    "        title='Grid, Source (purple) / Sink (red)', \n",
    "        vmin=-1, vmax=1, cmap=mcolors.ListedColormap(['purple', 'orange']), \n",
    "        node_size=node_size\n",
    "        )\n",
    "\n",
    "    plot_graph(data, snbs, ax=axs[1], title='True SNBS', vmin=vmin, vmax=vmax, \n",
    "        node_size=node_size)\n",
    "    nodes = plot_graph(data, pred_snbs, ax=axs[2], title='Predicted SNBS', \n",
    "                    vmin=vmin, vmax=vmax, add_colorbar=True, \n",
    "                    colorbar_label='SNBS', \n",
    "        node_size=node_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "data = data_ds100['train_ds'].dataset[0]\n",
    "pred_snbs = tag_module(data).detach().numpy()\n",
    "plt_snbs(data, pred_snbs, node_size=30)\n",
    "plt.savefig('sample_graph_100.png')\n",
    "plt.show()\n",
    "\n",
    "data = data_ds20['train_ds'].dataset[0]\n",
    "pred_snbs = tag_module(data).detach().numpy()\n",
    "plt_snbs(data, pred_snbs, node_size=100)\n",
    "plt.savefig('sample_graph_20.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size=100. \n",
    "min(max(20., 0.3*node_size), 10.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uda_project_autumn_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
